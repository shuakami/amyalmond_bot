import asyncio
import time
import httpx
from core.utils.logger import get_logger
from core.llm.llm_client import LLMClient
from config import REQUEST_TIMEOUT

_log = get_logger()


class OpenAIClient(LLMClient):
    """
    OpenAI API å®¢æˆ·ç«¯ï¼Œå®ç°äº† LLMClient æ¥å£ã€‚
    """

    async def on_message(self, message, reply_message):
        pass

    def __init__(self, openai_secret, openai_model, openai_api_url):
        self.openai_secret = openai_secret
        self.openai_model = openai_model
        self.openai_api_url = openai_api_url

        # åˆå§‹åŒ– last_request_time å’Œ last_request_content
        self.last_request_time = 0
        self.last_request_content = None

        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–è¶…æ—¶è®¾ç½®ï¼Œé»˜è®¤ä¸º7ç§’
        self.timeout = REQUEST_TIMEOUT or 7

    async def get_response(self, context, user_input, system_prompt, retries=2):
        """
        æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥,ä» OpenAI æ¨¡å‹è·å–å›å¤

        å‚æ•°:
            context (list): å¯¹è¯ä¸Šä¸‹æ–‡,åŒ…å«ä¹‹å‰çš„å¯¹è¯å†…å®¹
            user_input (str): ç”¨æˆ·çš„è¾“å…¥å†…å®¹
            system_prompt (str): ç³»ç»Ÿæç¤º
            retries (int): å‡ºç°é”™è¯¯æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤å€¼ä¸º2æ¬¡

        è¿”å›:
            str: OpenAI æ¨¡å‹ç”Ÿæˆçš„å›å¤å†…å®¹

        å¼‚å¸¸:
            httpx.HTTPStatusError: å½“è¯·æ±‚ OpenAI API å‡ºç°é—®é¢˜æ—¶å¼•å‘
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚
        if time.time() - self.last_request_time < 0.6 and user_input == self.last_request_content and "<get memory>" not in user_input:
            _log.warning("<DUPLICATE> æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå·²å¿½ç•¥:")
            _log.warning(f"   â†³ ç”¨æˆ·è¾“å…¥: {user_input}")
            return None

        payload = {
            "model": self.openai_model,
            "temperature": 0.85,
            "top_p": 1,
            "presence_penalty": 1,
            "max_tokens": 3450,
            "messages": [
                            {"role": "system", "content": system_prompt}
                        ] + context + [
                            {"role": "user", "content": user_input}
                        ]
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.openai_secret}"
        }

        # è®°å½•è¯·æ±‚çš„ payload å’Œ headers
        _log.debug("<REQUEST> è¯·æ±‚å‚æ•°:")
        _log.debug(f"   â†³ Payload: {payload}")
        _log.debug(f"   â†³ Headers: {headers}")

        for attempt in range(retries + 1):
            try:
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await client.post(self.openai_api_url, headers=headers, json=payload)
                    response.raise_for_status()
                    response_data = response.json()

                # è®°å½•å®Œæ•´çš„å“åº”æ•°æ®
                _log.debug("<RESPONSE> å®Œæ•´å“åº”æ•°æ®:")
                _log.debug(f"   â†³ {response_data}")

                reply = response_data['choices'][0]['message']['content'] if 'choices' in response_data and \
                                                                             response_data['choices'][0]['message'][
                                                                                 'content'] else None

                # æ›´æ–° last_request_time å’Œ last_request_content
                self.last_request_time = time.time()
                self.last_request_content = user_input

                if reply is None:
                    _log.warning("<RESPONSE> OpenAI å›å¤ä¸ºç©º:")
                    _log.warning(f"   â†³ ç”¨æˆ·è¾“å…¥: {user_input}")
                else:
                    # è®°å½• OpenAI çš„å›å¤å†…å®¹
                    _log.info("<RESPONSE> OpenAI å›å¤:")
                    _log.info(f"   â†³ å†…å®¹: {reply}")

                return reply

            except httpx.HTTPStatusError as e:
                _log.error("<ERROR> ğŸš¨è¯·æ±‚é”™è¯¯:")
                _log.error(f"   â†³ çŠ¶æ€ç : {e.response.status_code}")
                _log.error(f"   â†³ é”™è¯¯è¯¦æƒ…: {e}")
                _log.error(f"   â†³ è¿”å›å†…å®¹: {e.response.text}")
                if e.response.status_code in {503, 504, 500}:  # å¤„ç†å¸¸è§é”™è¯¯çŠ¶æ€ç 
                    _log.info(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{e.response.status_code}ã€‚æ­£åœ¨å°è¯•é‡è¯•...({attempt + 1}/{retries})")
                    if attempt < retries:
                        await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                        continue
                return f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{e.response.status_code}ã€‚è¯·ç¨åå†è¯•ã€‚"


            except httpx.RequestError as e:
                _log.error("<ERROR> è¯·æ±‚å¼‚å¸¸:")
                _log.error(f"   â†³ é”™è¯¯è¯¦æƒ…: {e}")
                _log.error(f"   â†³ é”™è¯¯ç±»å‹: {type(e)}")
                if attempt < retries:
                    _log.info(f"è¯·æ±‚å¼‚å¸¸ï¼Œæ­£åœ¨å°è¯•é‡è¯•...({attempt + 1}/{retries})")
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                return "è¯·æ±‚è¶…æ—¶æˆ–ç½‘ç»œé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚"


            except Exception as e:

                _log.error("<ERROR> æœªçŸ¥é”™è¯¯:")
                _log.error(f"   â†³ é”™è¯¯è¯¦æƒ…: {e}")
                _log.error(f"   â†³ é”™è¯¯ç±»å‹: {type(e)}")
                if attempt < retries:
                    _log.info(f"å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œæ­£åœ¨å°è¯•é‡è¯•...({attempt + 1}/{retries})")
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue

                return "å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚"

        return "è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def test(self):
        """
        æµ‹è¯• OpenAIClient ç±»çš„æ–¹æ³•
        """
        context = [
            {"role": "user", "content": "ä½ å¥½ï¼"}
        ]
        user_input = "ä½ è¿˜è®°å¾—æˆ‘ä¹‹å‰è¯´äº†å¤šå°‘ä¸ªâ€œä½ å¥½â€å—"
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚"

        response = await self.get_response(context, user_input, system_prompt)
        print("API Response:", response)


# ä½¿ç”¨æ–¹æ³•
if __name__ == "__main__":
    # é…ç½® OpenAIClient
    openai_secret = "sk-s2lDjPP1AdigpPBO53845f5d134a406d96CbE24aEeBe2d36"
    openai_model = "Meta-Llama-3.1-8B-Instruct"
    openai_api_url = "https://ngedlktfticp.cloud.sealos.io/v1/chat/completions"
    # æˆ‘å¯ä»¥æŠŠæˆ‘çš„ç§˜é’¥å…¬å¼€ï¼Œå› ä¸ºé¢åº¦å¾ˆå°ï¼Œè€Œä¸”æ˜¯ç”¨æ¥æµ‹è¯•çš„ã€‚ä½†ä½ ä¸€å®šä¸è¦åƒæˆ‘ä¸€æ ·æŠŠç§˜é’¥æ˜æ–‡å†™åœ¨ä»£ç ä¸­ã€‚

    # åˆ›å»º OpenAIClient å®ä¾‹
    client = OpenAIClient(openai_secret=openai_secret, openai_model=openai_model, openai_api_url=openai_api_url)

    # è¿è¡Œæµ‹è¯•
    asyncio.run(client.test())
