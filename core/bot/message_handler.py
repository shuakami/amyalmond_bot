"""
AmyAlmond Project - message_handler.py

Open Source Repository: https://github.com/shuakami/amyalmond_bot
Developer: Shuakami <3 LuoXiaoHei
Copyright (c) 2024 Amyalmond_bot. All rights reserved.
Version: 1.2.3 (Alpha_829001)

message_handler.py è´Ÿè´£å¤„ç†ç¾¤ç»„æ¶ˆæ¯ï¼ŒåŒ…æ‹¬åŠ¨æ€æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†ã€æ™ºèƒ½è®°å¿†æ³¨å…¥ã€ä¸Elasticsearché›†æˆç­‰åŠŸèƒ½ã€‚
"""

import asyncio

from botpy.message import GroupMessage
from botpy.types.message import Reference

from config import MAX_CONTEXT_TOKENS
from core.bot.memory_utils import process_reply_content, handle_long_term_memory, manage_memory_insertion
# user_registration.pyæ¨¡å— - <å¤„ç†æ–°ç”¨æˆ·æ³¨å†Œ>
from core.bot.user_registration import handle_new_user_registration
# elasticsearch_index_manager.pyæ¨¡å— - <ç”¨äºä¸Elasticsearchäº¤äº’>
from core.db.elasticsearch_index_manager import ElasticsearchIndexManager
# logger.pyæ¨¡å— - <æ—¥å¿—è®°å½•æ¨¡å—>
from core.utils.logger import get_logger
# user_management.pyæ¨¡å— - <ç”¨äºç”¨æˆ·å†…å®¹æ¸…ç†ã€ç”¨æˆ·åè·å–ã€ç”¨æˆ·æ³¨å†Œæ£€æŸ¥åŠæ–°å¢ç”¨æˆ·å¤„ç†>
from core.utils.user_management import clean_content, get_user_name, is_user_registered
# utils.pyæ¨¡å— - <ä»å›å¤æ¶ˆæ¯ä¸­æå–è®°å¿†å†…å®¹>
from core.utils.utils import calculate_token_count

_log = get_logger()


class MessageHandler:
    """
    è´Ÿè´£å¤„ç†ç¾¤ç»„æ¶ˆæ¯çš„ç±»ï¼ŒåŒ…æ‹¬æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†ã€è®°å¿†æ³¨å…¥ã€æ–°ç”¨æˆ·æ³¨å†Œã€æ™ºèƒ½æŸ¥è¯¢é€‰æ‹©ç­‰åŠŸèƒ½ã€‚
    """

    def __init__(self, client, memory_manager):
        """
        åˆå§‹åŒ– MessageHandler å®ä¾‹ï¼Œåˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—ã€é”ã€å¤„ç†æ¶ˆæ¯IDçš„é›†åˆå’Œäº‹ä»¶å¾ªç¯

        å‚æ•°:
            client (BotClient): æœºå™¨äººå®¢æˆ·ç«¯å®ä¾‹
            memory_manager (MemoryManager): è®°å¿†ç®¡ç†å™¨å®ä¾‹
        """
        self.client = client
        self.memory_manager = memory_manager
        self.es_manager = ElasticsearchIndexManager()  # åˆå§‹åŒ–Elasticsearchç®¡ç†å™¨
        self.message_queues = {}  # æ¯ä¸ªç¾¤ç»„ä¸€ä¸ªæ¶ˆæ¯é˜Ÿåˆ—
        self.locks = {}  # æ¯ä¸ªç¾¤ç»„ä¸€ä¸ªé”
        self.processed_messages: set[int] = set()   # è®°å½•å·²ç»å¤„ç†è¿‡çš„æ¶ˆæ¯ID
        self.queue_loop = asyncio.get_event_loop()  # åˆ›å»ºä¸€ä¸ªäº‹ä»¶å¾ªç¯

    async def handle_group_message(self, message: GroupMessage):
        """
        å¤„ç†æ”¶åˆ°çš„ç¾¤ç»„æ¶ˆæ¯ï¼Œåˆ†å‘åˆ°ç›¸åº”çš„æ¶ˆæ¯é˜Ÿåˆ—ä¸­ï¼Œå¹¶å¯åŠ¨æ¶ˆæ¯å¤„ç†ä»»åŠ¡

        å‚æ•°:
            message (GroupMessage): æ”¶åˆ°çš„ç¾¤ç»„æ¶ˆæ¯
        """
        group_id = message.group_openid
        user_id = message.author.member_openid
        user_name = get_user_name(user_id)
        cleaned_content = clean_content(message.content)
        message_id = message.id

        # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç†
        if message_id in self.processed_messages:
            _log.info(f"<SKIP> æ¶ˆæ¯ {message_id} å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡ã€‚")
            return

        _log.info(f"<RECEIVED> æ–°æ¶ˆæ¯ +++++++++++++")
        _log.info(f"   â†³ ç”¨æˆ·: {user_name} ({user_id})")
        _log.info(f"   â†³ ç¾¤ç»„: {group_id}")
        _log.info(f"   â†³ å†…å®¹: '{cleaned_content}'")
        _log.info("")

        # æ·»åŠ æ¶ˆæ¯IDåˆ°å·²å¤„ç†é›†åˆä¸­
        self.processed_messages.add(message_id)

        # æ¸…ç†è¿‡æœŸçš„æ¶ˆæ¯IDä»¥é¿å…é›†åˆè¿‡å¤§
        if len(self.processed_messages) > 1000:
            _log.debug("<CLEANUP> æ¸…ç†è¿‡æœŸçš„æ¶ˆæ¯ID...")
            self.processed_messages = set(list(self.processed_messages)[-500:])

        # ä¸ºæ–°çš„ç¾¤ç»„åˆå§‹åŒ–é˜Ÿåˆ—å’Œé”
        if group_id not in self.message_queues:
            _log.debug(f"<INIT> åˆå§‹åŒ–ç¾¤ç»„ {group_id} çš„æ¶ˆæ¯é˜Ÿåˆ—å’Œé”...")
            self.message_queues[group_id] = asyncio.Queue()
            self.locks[group_id] = asyncio.Semaphore(1)

        # ä½¿ç”¨äº‹ä»¶æ€»çº¿å°†æ¶ˆæ¯å‘å¸ƒå‡ºå»ï¼Œæ’ä»¶å¯ä»¥åœ¨æ­¤æ—¶å¯¹æ¶ˆæ¯è¿›è¡Œå¤„ç†
        await self.client.plugin_manager.event_bus.publish("before_message_queue", message, cleaned_content)

        # å°†æ¶ˆæ¯æ”¾å…¥å¯¹åº”ç¾¤ç»„çš„é˜Ÿåˆ—ä¸­
        await self.message_queues[group_id].put((user_name, cleaned_content, message))
        _log.debug(f"<QUEUE> æ¶ˆæ¯å·²åŠ å…¥ç¾¤ç»„ {group_id} çš„é˜Ÿåˆ—")
        await self.process_message_queue(group_id)

    async def process_message_queue(self, group_id):
        async with self.locks[group_id]:  # ç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªä»»åŠ¡åœ¨å¤„ç†è¯¥ç¾¤ç»„çš„æ¶ˆæ¯
            _log.debug(f"<PROCESS> å¼€å§‹å¤„ç†ç¾¤ç»„ {group_id} çš„æ¶ˆæ¯é˜Ÿåˆ—...")
            while not self.message_queues[group_id].empty():
                user_name, cleaned_content, message = await self.message_queues[group_id].get()

                try:
                    _log.debug("<PMQ æ¶ˆæ¯é˜Ÿåˆ—> ğŸš€å¼€å§‹å¤„ç†æ¶ˆæ¯")
                    _log.debug(f"   â†³ ç¾¤ç»„: {group_id}")
                    _log.debug(f"   â†³ ç”¨æˆ·: {user_name} ({message.author.member_openid})")
                    _log.debug(f"   â†³ å†…å®¹: '{cleaned_content}'")

                    # å¤„ç†ç®¡ç†å‘˜æŒ‡ä»¤
                    if message.author.member_openid == self.client.ADMIN_ID:
                        if cleaned_content.strip().lower() == "restart":
                            _log.info("<ADMIN> æ”¶åˆ°ç®¡ç†å‘˜restartå‘½ä»¤:")
                            _log.info("   â†³ é‡å¯æœºå™¨äºº")
                            await self.client.restart_bot(group_id, message.id)
                            continue
                        elif cleaned_content.strip().lower() == "reload":
                            _log.info("<ADMIN> æ”¶åˆ°ç®¡ç†å‘˜reloadå‘½ä»¤:")
                            _log.info("   â†³ é‡æ–°åŠ è½½é…ç½®")
                            await self.client.hot_reload(group_id, message.id)
                            continue

                    # å¤„ç†æ–°ç”¨æˆ·æ³¨å†Œ
                    if not is_user_registered(message.author.member_openid):
                        _log.info(f"<REGISTER> ç”¨æˆ· {message.author.member_openid} å°šæœªæ³¨å†Œï¼Œæ­£åœ¨å¤„ç†æ³¨å†Œ...")
                        await handle_new_user_registration(self.client, group_id, message.author.member_openid,
                                                           cleaned_content, message.id)
                        continue

                    # åœ¨å¤„ç†æ¶ˆæ¯ä¹‹å‰ï¼Œé€šè¿‡äº‹ä»¶æ€»çº¿è§¦å‘æ’ä»¶é€»è¾‘
                    await self.client.plugin_manager.event_bus.publish("before_message_process", message,
                                                                       cleaned_content)

                    _log.debug(f"<COMPRESS> æ­£åœ¨å‹ç¼©ç¾¤ç»„ {group_id} çš„æ¶ˆæ¯å†å²...")
                    context = await self.memory_manager.compress_memory(group_id, self.client.get_gpt_response)

                    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•ä¸­
                    formatted_message = f"{user_name}: {cleaned_content}"
                    _log.debug(f"<HISTORY> æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•: {formatted_message}")
                    self.memory_manager.add_message_to_history(group_id, {"role": "user", "content": formatted_message})
                    context = await manage_memory_insertion(self.memory_manager, group_id, cleaned_content, context,
                                                            formatted_message)
                    # åŠ¨æ€æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦è°ƒæ•´ - åŸºäºTokenè®¡æ•°
                    current_token_count = calculate_token_count(context)
                    _log.debug(f"<TOKENS> å½“å‰Tokenè®¡æ•°: {current_token_count}")
                    while current_token_count > MAX_CONTEXT_TOKENS:
                        context = context[1:]  # ç§»é™¤æœ€æ—©çš„ä¸€æ¡æ¶ˆæ¯
                        current_token_count = calculate_token_count(context)
                        _log.debug(f"<TOKENS> ç§»é™¤æœ€æ—©æ¶ˆæ¯åTokenè®¡æ•°: {current_token_count}")

                    # åœ¨è·å– LLM å›å¤ä¹‹å‰ï¼Œå‘å¸ƒäº‹ä»¶ä»¥å…è®¸æ’ä»¶è¿›è¡Œå¤„ç†
                    await self.client.plugin_manager.event_bus.publish("before_llm_response", context,
                                                                       formatted_message)

                    # è·å– LLM çš„å›å¤
                    context = [msg for msg in context if msg.get('content') and msg['content'].strip()]
                    _log.debug("<LLM> æ­£åœ¨è·å–LLMå›å¤...")
                    reply_content = await self.client.get_gpt_response(context, formatted_message)

                    # å¦‚æœè·å– LLM å›å¤å¤±è´¥ï¼Œåˆ™è·³è¿‡å½“å‰æ¶ˆæ¯çš„å¤„ç†
                    if reply_content is None:
                        _log.warning("   â†³ æœªèƒ½è·å–LLMå›å¤ï¼Œè·³è¿‡æ­¤æ¶ˆæ¯çš„å¤„ç†")
                        continue

                    # å¤„ç†é•¿è®°å¿†çš„æƒ…å†µ
                    if "<get memory>" in reply_content:
                        _log.debug("<MEMORY> LOADING")
                        _log.debug(">>> ğŸ”„æ£€æµ‹åˆ° <get memory> æ ‡è®°ï¼Œæ­£åœ¨æ£€ç´¢é•¿è®°å¿†...")
                        reply_content = await handle_long_term_memory(self.memory_manager, group_id, cleaned_content,
                                                                      formatted_message, context, self.client)
                    # æå–å¹¶å­˜å‚¨æ–°è®°å¿†å†…å®¹
                    reply_content = await process_reply_content(self.memory_manager, group_id, message, reply_content)

                    # ç”Ÿæˆå¹¶å‘é€å›å¤æ¶ˆæ¯ï¼ŒåŒ…å«æ¶ˆæ¯å¤„ç†æ—¶é—´
                    reply_message = reply_content or 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›å¤ä½ çš„æ¶ˆæ¯'

                    _log.debug(f"<PLUGIN> æ’ä»¶å¤„ç†å‰çš„æ¶ˆæ¯: {reply_message}")

                    # ä½¿ç”¨äº‹ä»¶æ€»çº¿è°ƒç”¨æ’ä»¶å¤„ç†å›å¤æ¶ˆæ¯
                    plugin_result = await self.client.plugin_manager.event_bus.publish("before_send_reply", message,
                                                                                       reply_message)
                    if plugin_result is not None:
                        reply_message = plugin_result

                    _log.debug(f"<PLUGIN> æ’ä»¶å¤„ç†åçš„æ¶ˆæ¯: {reply_message}")

                    # å‘é€æœ€ç»ˆçš„å›å¤æ¶ˆæ¯
                    _log.info("<SEND> å‘é€å›å¤æ¶ˆæ¯:")
                    _log.info(f"   â†³ ç›®æ ‡ç¾¤ç»„: {group_id}")
                    _log.info(f"   â†³ å›å¤å†…å®¹: {reply_message}")
                    message_reference = Reference(message_id=message.id, ignore_get_message_error=True)
                    await self.client.api.post_group_message(
                        group_openid=group_id,
                        content=reply_message,
                        msg_id=message.id,
                        message_reference=message_reference
                    )

                    # å°†ç”¨æˆ·æ¶ˆæ¯å’Œæœºå™¨äººçš„å›å¤å­˜å‚¨åˆ°æ•°æ®åº“
                    _log.debug(">>> å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“...")
                    await self.memory_manager.store_memory(group_id, message, "user", formatted_message)
                    _log.debug(">>> å­˜å‚¨æœºå™¨äººå›å¤åˆ°æ•°æ®åº“...")
                    await self.memory_manager.store_memory(group_id, message, "assistant", reply_content)

                except Exception as e:
                    _log.error(f"<ERROR> ğŸš¨å¤„ç†ç¾¤ç»„ {group_id} çš„æ¶ˆæ¯æ—¶å‡ºé”™:")
                    _log.error(f"   â†³ é”™è¯¯è¯¦æƒ…: {e}", exc_info=True)
                finally:
                    _log.debug("<COMPLETE> æ¶ˆæ¯å¤„ç†å®Œæˆï¼Œæ ‡è®°ä»»åŠ¡å®Œæˆ")
                    self.message_queues[group_id].task_done()


    @staticmethod
    def is_critical_context_present(context, content):
        """
        æ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦åŒ…å«ä¸å½“å‰æ¶ˆæ¯ç›¸å…³çš„å…³é”®ä¿¡æ¯ã€‚
        å¦‚æœä¸Šä¸‹æ–‡ä¸­å·²ç»åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
        """
        # æ ¹æ®å…³é”®å­—æˆ–è¯­ä¹‰åˆ†æåˆ¤æ–­æ˜¯å¦å­˜åœ¨å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯
        for msg in context:
            if content in msg['content']:
                return True
        return False